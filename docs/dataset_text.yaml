# Contains custom text for various entries in the generated ReadTheDocs documentation
#
# Each entry is associated with a key that is injected into the documentation generated
# from the data model .csv files.

datasets:
  "conus1_domain":
    summary: >
      The ParFlow CONUS1 model is the first generation national ParFlow model. You can learn more about the domain and the model on the `HydroFrame Website <https://hydroframe.org/parflow-conus1/>`_. The `conus1_domain` dataset contains all of the input fields for the model as well as additional pre and post processing files that can be useful for data analysis. If you are interested in building a ParFlow model off of this national template the `Subset Tools python package` can help you do that. Refer to the documentation `here <https://hydroframesubsettools.readthedocs.io/en/latest/>`_


  "conus2_domain":
    summary: >
      The ParFlow CONUS2 model is the second generation national ParFlow model. The CONUS2 domain covers the entire contiguous US and areas draining to it. The domain extent and projection are based off of the National Water Model Grid. Manual corrections were made along the coastline to get rid of cells that were water and to prune any orphan cells (i.e. cells attached to the domain only by a corner).  You can learn more about the domain and the model on the `HydroFrame Website <https://hydroframe.org/parflow-conus2/>`_. The `conus2_domain` dataset contains all of the input fields for the model as well as additional pre and post processing files that can be useful for data analysis. If you are interested in building a ParFlow model off of this national template the `SubsetTools Python package <https://github.com/hydroframe/subsettools/tree/main>`_ can help you do that. Refer to the documentation `here <https://hydroframesubsettools.readthedocs.io/en/latest/>`_.

  "conus1_baseline_85":
    summary: >
      A simulation of water year 1985 completed with the ParFlow CONUS1 model.  This was the first transient simulation that was completed with the ParFlow CONUS1 model. The simulation was completed using the NLDAS2 forcing dataset at 1km resolution and a 1 hour time step.  This dataset contains all of the outputs from the simulation as well as the ParFlow and CLM run scripts.  The model inputs can be found in the `conus1_domain <https://hf-hydrodata.readthedocs.io/en/latest/gen_conus1_domain.html>`_ dataset. Refer to the citations below for additional information on the model development and findings. 

  "conus1_baseline_mod":
    summary: >
      A simulation of water years 2003-2006 completed with the ParFlow CONUS1 model.  This is the most recent transient simulation that was completed with the ParFlow CONUS1 model (i.e. after the `conus_baseline_85 <https://hf-hydrodata.readthedocs.io/en/latest/gen_conus1_baseline_85.html>`_ simulation). The simulation was completed using the NLDAS2 forcing dataset at 1km resolution and a 1 hour time step.  This dataset contains all of the outputs from the simulation as well as the ParFlow and CLM run scripts.  The model inputs can be found in the `conus1_domain <https://hf-hydrodata.readthedocs.io/en/latest/gen_conus1_domain.html>`_ dataset. Refer to the citations below for additional information on the model development and findings. 

  "NLDAS2":
    summary: The NLDAS grid is a 1/8th degree grid that covers the entire contiguous US.  This dataset contains the NLDAS2 forcing data at 1/8th degree resolution and a 1 hour time step.  This dataset was used to force the `conus1_baseline_mod <https://hf-hydrodata.readthedocs.io/en/latest/gen_conus1_baseline_mod.html>`_ simulation.  This dataset is adjusted and bias corrected per the description in `O'Neill et al GMD 2021 <https://gmd.copernicus.org/articles/14/7223/2021/>`_. 

    processing_notes: Heavily bias corrected per `O'Neill et al GMD 2021 <https://gmd.copernicus.org/articles/14/7223/2021/>`_.  The bias correction is applied to the NLDAS2 data before it is bilinearly interpolated to the ParFlow CONUS1 grid. 

  "NLDAS2_85":
    summary: The NLDAS2 forcing dataset at 1km resolution and a 1 hour time step.  This dataset was used to force the `conus1_baseline_85 <https://hf-hydrodata.readthedocs.io/en/latest/gen_conus1_baseline_85.html>`_ simulation.  This dataset is bilinearly interpolated to the ParFlow CONUS1 grid.  The original NLDAS2 dataset can be found `here <https://ldas.gsfc.nasa.gov/nldas>`_.

    processing_notes: Bilinearly interpolated from the native resolution to 1km.

  "CW3E":
    summary: An hourly meteorological forcing product at 1km resolution over the `CONUS2 <https://hydroframe.org/parflow-conus2>`_ domain. Please see the `detailed documentation <https://www.reachhydro.org/home/records/1-km-conus-forcing>`_ as well as the version release notes below for additional details. We recommend using the latest version, 1.0. 

    processing_notes: >
      ....

    version_notes: >
      **Version 1.0**: Second HydroFrame release of the CW3E dataset.
      
      Updates from version 0.9:

      CW3E team: corrected an 11-hour (for P) and 12-hour (for T) time mismatch against PRISM.

      HydroFrame team: implemented some additional adjustments to temperature and specific humidity for Water Years 2003-2005 at the HUC02
      level. Temperature was adjusted as described for each region below. Specific humidity was adjusted anywhere that temperature was 
      adjusted, using the Clausius-Clapeyron equation.

      - Water Year 2003: 
        - Great Basin (HUC 16): 0.5 degree uniform temperature decrease
        - Pacific Northwest (HUC 17): 0.5 degree uniform temperature decrease
        - Upper Colorado River Basin (HUC 14): temperature lapse rate correction at 4 K/km  

      - Water Year 2004: 
        - Great Basin (HUC 16): 0.5 degree uniform temperature decrease
        - Upper Colorado River Basin (HUC 14): temperature lapse rate correction at 4 K/km 
      
      - Water Year 2005: 
        - Upper Colorado River Basin (HUC 14): temperature lapse rate correction at 2.5 K/km 


      **Version 0.9**: Initial version of CW3E dataset.

  "huc_mapping":
    summary: >
      USGS Hydrologic unit codes have been mapped to the CONUS1 and CONUS2 grids. This mapping generally respects the boundaries provided in the USGS shape files however small adjustments were made to ensure that the watershed boundaries align with topographic boundaries in the CONUS1 and CONUS2 domains.  This dataset contains mappings for ... 

    processing_notes: >
      ....

  "conus1_current_conditions":
    summary: >
      ...

    processing_notes: >
      ....

  "conus2_current_conditions":
    summary: >
      ...

    processing_notes: >
      ....

  "nasa_smap":
    summary: >

      Soil Moisture data from the `NASA SMAP web service <https://cmr.earthdata.nasa.gov>`_, for
      the entire world.  Data is clipped to a region 1 degree larger than than the CONUS 2 region 
      and saved to water year netcdf files. 
      The produced netcdf file contains 6 variables. Below are the variables and their descriptions

        - TimeStamp The Date stamps of the downloaded data.
        - Longitude- A single matrix representing all of the longitude points.
        - Latitude- A single matrix representing all of the latitude points.
        - SoilMoisture- A matrix for each date of data downloaded (in other words, a matrix for each date present in the TimeStamp variable).  A whole wateryear file will contain 365 matrices in a normal year, or 366 for a leap year, one representing each day. The soil moisture data here is calculated as the mean between the AM and PM values, as downloaded from the NASA website. A RetrievalQualFlag is given for each AM data and PM data used, as described below.  The latitude and longitude matrices are the same size as the Soil Moisture, RetrievalQualFlagAM, and RetrievalQualFlagPM matrices, and together, they represent the (latitude, longitude) point for which each soil moisture data point, RetrievalQualFlagAM, and RetrievalQualFlagPM, was collected.
        - RetrievalQualFlagAM- A matrix for each date of data downloaded representing the data quality of the AM data collected. A whole wateryear file will contain 365 matrices in a normal year, or 366 for a leap year, one representing each day.
        - RetrievalQualFlagPM- A matrix for each date of data downloaded represening the data quality of the PM data collected. A whole wateryear file will contain 365 matrices in a normal year, or 366 for a leap year, one representing each day.
              
      On occassion, some days of data are not available from the NASA website.  In these instances, 
      a row for that date will be entered with None values for the data.

    processing_notes: >
      We query data from the NASA SMAP weekly, early on Sunday mornings.  All previous
      data, up through the most recently available data from the SMAP website,
      is collected.

  "usgs_nwis":
    summary: >
      Streamflow and groundwater data from the USGS National Water Information System (NWIS) database.
      
        - Daily streamflow and water table depth data are obtained from the `Daily Values Service <https://waterservices.usgs.gov/docs/dv-service/daily-values-service-details/>`_.  

        - Hourly streamflow and water table depth data are aggregated to the hourly level from the `Instantaneous Values Service <https://waterservices.usgs.gov/docs/instantaneous-values/instantaneous-values-details/>`_, which are frequently collected at 15-minute increments.   

        - The water table depth data accessed with `temporal_resolution='instantaneous'` comes from the USGS `Groundwater Levels Service <https://waterservices.usgs.gov/docs/groundwater-levels/groundwater-levels-details/>`_. Note that these data usually do not have regular temporal coverage and many of the sites with data available through this method only have a single point-in-time observation available.  

    processing_notes: >
      We query data from the USGS weekly, early on Sunday mornings. Each weekly job collects all observations since the date through which we have existing data stored. For sites that are currently in operation, this translates to collecting data for only the previous week (7 days for daily data, 168 hours for hourly data). 
      
      Because of the sparsity of the `temporal_resolution='instantaneous'` groundwater measurements, those are not included in this weekly schedule. We plan to query that source for new observations roughly every few months.

      Note that raw hourly data is saved in UTC while raw daily data is saved with respect to the local site time zone. 

      To maintain the integrety and traceability back to the original sources, our team conducts very limited data manipulation on the queried data. This includes the following:

      - Unit translation into SI units  
      - Standardization of NaN/missing values
        - For example, USGS will sometimes provide strings such as "Ice" or "Dry" to indicate reasons for why certain observations are missing. A full list of such fields is available `here <https://help.waterdata.usgs.gov/codes-and-parameters/instantaneous-and-daily-value-status-codes>`_.
    
        We standardize these values into the numeric numpy.NaN to allow the entireity of the series to be interpreted as numeric.
    
      - Consolidating multiple concurrent data series
        - The USGS data sometimes provides multiple concurrent observation series for the same variable for the same site. In these cases, we consolidate the multiple series into a single series following these prioritizations:
        - If one of the series has been verified, we prioritize that over provisional data
        - If both series are identical values, we simply reduce down to a single set of observations
        - If one of the series has non-missing data and the other series has missing data, we prioritize the non-missing data
        - If multiple series remain with conflicting values, we take the average of the resulting non-missing values

  "snotel":
    summary: >
      Snow measurements provided through through the  `Snow Telemetry (SNOTEL) network <https://www.nrcs.usda.gov/wps/portal/wcc/home/aboutUs/monitoringPrograms/automatedSnowMonitoring/#:~:text=SNOTEL%20sites%20are%20designed%20to,used%20to%20keep%20batteries%20charged.>`_.

      Data are accessed through the United States Department of Agriculture (USDA) Natural Resources Conservation Service (NRCS) `Air Water Database <https://www.nrcs.usda.gov/wps/portal/wcc/home/dataAccessHelp/webService>`_.

    processing_notes: >
      We query data from the Air Water Database weekly, early on Sunday mornings. Each weekly job collects all observations since the date through which we have existing data stored. For sites that are currently in operation, this translates to collecting data for only the previous week (7 days for daily data, 168 hours for hourly data). 
      
      Note that raw hourly data is saved in UTC while raw daily data is saved with respect to the local site time zone. 

      To maintain the integrity and traceability back to the original sources, our team conducts very limited data manipulation on the queried data. This includes the following:

      - Unit translation into SI units  
      - Standardization of NaN/missing values

  "scan":
    summary: >
      Observations of soil conditions from the `Soil Climate Analysis Network (SCAN) <https://www.nrcs.usda.gov/resources/data-and-reports/soil-climate-analysis-network>`_.

      The data are obtained from the United States Department of Agriculture (USDA) Natural Resources Conservation Service (NRCS) `Air Water Database <https://www.nrcs.usda.gov/wps/portal/wcc/home/dataAccessHelp/webService>`_.

    processing_notes: >
      We query data from the Air Water Database, early on Sunday mornings. Each weekly job collects all observations since the date through which we have existing data stored. For sites that are currently in operation, this translates to collecting data for only the previous week (7 days for daily data, 168 hours for hourly data). 
      
      Note that raw hourly data is saved in UTC while raw daily data is saved with respect to the local site time zone. 

      To maintain the integrity and traceability back to the original sources, our team conducts very limited data manipulation on the queried data. This includes the following:

      - Unit translation into SI units  
      - Standardization of NaN/missing values

  "ameriflux":
    summary: >
      Observations of land energy fluxes from observation towers in the AmeriFlux network. Data are obtained  from the `AmeriFlux <https://ameriflux.lbl.gov/data/data-policy/>`_ network.

    processing_notes: >
      We query data from AmeriFlux monthly. Each monthly job collects all observations available for sites that report on our supported variables.
      
      Note that raw hourly data is saved in UTC while raw daily data is saved with respect to the local site time zone. 

      To maintain the integrity and traceability back to the original sources, our team conducts very limited data manipulation on the queried data. This includes the following:

      - Unit translation into SI units  
      - Standardization of NaN/missing values

      - Consolidating multiple concurrent data series
        - The AmeriFlux data sometimes provides multiple concurrent observation series for the same variable for the same site. In these cases, we consolidate the multiple series into a single series following these prioritizations:
        - We prioritize series without any suffix in the original variable names. If none is present, we prioritize variables with a "PI" suffix in the variable name, to indicate the data has been QA/QC reviewed by the tower team. 

  "jasechko_2024":
    summary: >
      A subset of the annual median water table depth measurements for sites included in `Jasechko et al. 2024 <https://www.nature.com/articles/s41586-023-06879-8>`_.
      These sites are subset to only those within the `CONUS2 <https://hydroframe.org/parflow-conus2>`_ boundary, and only includes data that the authors were approved to publicly release. 

    processing_notes: >
      Details on the initial data processing and collection are provided in `Jasechko et al. 2024 <https://www.nature.com/articles/s41586-023-06879-8>`_.
      The data provided here was acquired from https://zenodo.org/records/10003697. Data was filtered to the CONUS2 domain and all sites
      were also mapped to the Natural Earth state boundary shapefiles to include each site's state, where this mapping was unambiguous.

      All sites were compared to existing USGS well records. If a site was within 0.001 degree latitude/longitude of an existing well, the
      site is flagged as being a usgs_site.

      Notes:

      - The data included here is only a subset of the data in the original paper as not all data was made publicly available. 
       
      - The data included in this dataset are a static entry matching only what was in the publication. For up to date groundwater records refer to the USGS well dataset which is updated regularly with the most recent observations.

  "fan_2013":
    summary: >
      A subset of the site-level long-term mean water table depth measurements for sites included in `Fan et al. 2013 <https://www.science.org/doi/10.1126/science.1229881>`_. 
      These sites are subset to only those within the `CONUS2 <https://hydroframe.org/parflow-conus2>`_ boundary and 
      include data that the authors used in this publication and are up to 12/31/2009.

    processing_notes: >
      Details on the initial data processing and collection are provided in `Fan et al. 2013 <https://www.science.org/doi/10.1126/science.1229881>`_. 
      The data provided here was acquired from an offline communication with the main author. Data was filtered to the
      CONUS2 domain and all sites were also mapped to the Natural Earth state boundary shapefiles to include each site's state,
      where this mapping was unambiguous.

      This dataset contained site identifiers common with the USGS. Therefore, site-level attributes from the USGS are displayed for 
      sites that are still presently available in the USGS groundwater data portal.

      Notes:

      - The data included here is only a subset of the data in the original paper to the CONUS2 geographic domain.

      - The data included in this dataset are a static entry matching only what was in the publication. For up to date groundwater records refer to the `USGS NWIS well dataset <https://hf-hydrodata.readthedocs.io/en/latest/gen_usgs_nwis.html>`_, which is updated regularly with the most recent observations.

  "modis":
    summary: >
      A gridded mask of daily snow-on/snow-off coverage for the continental United States. MODIS satellite data was processed to 
      remove the effect of clouds and thereby improve usable coverage. This version of the dataset has been remapped from the 
      original 0.05 degree by 0.05 degree grid to the 1km by 1km CONUS2 grid.

    processing_notes: >
      The data provided here was acquired from https://figshare.com/articles/dataset/A_cloud-free_MODIS_snow_cover_dataset_for_the_contiguous_United_States_from_2000_to_2017/5902381/4.
      The data were created by subtracting cloud cover from NASA's Moderate Resolution Imaging Spectroradiometer (MODIS) 
      snow cover product using a variational interpolation algorithm. Details of the dataset creation and validation process 
      are described in detail in `Tran et al, 2019 <https://www.nature.com/articles/sdata2018300>`_. 

      The spatial resolution of the data is 0.05 by 0.05 degree, and the temporal resolution is daily from March 2000 to 
      February 2017. Several days are missing from select years due to `MODIS outages <https://modaps.modaps.eosdis.nasa.gov/services/production/outages_terra.html>`_.

      The data included in this dataset have been geospatially transformed from the 0.05 by 0.05 degree grid to the 1km by 1km CONUS2 grid.

  "ma_2023":
    summary: >
      Water table depth estimates provided by a random forest model trained on historical USGS observations 
      and `Fan et al. 2013 water table depth dataset <https://hf-hydrodata.readthedocs.io/en/latest/gen_fan_2013.html>`_. 
      This dataset includes long-term mean water table estimates and uncertainty at 1km resolution for the CONUS1 domain. 

    processing_notes: >
      Long-term mean water table depth estimates were obtained using the median of tree outputs from the trained random 
      forest model. The uncertainty was assessed based on the coefficient of variation of the tree outputs from the random 
      forest model, which was calculated as the standard deviation of the tree outputs divided by their mean.
